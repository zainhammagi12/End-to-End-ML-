# End-to-End Machine Learning Pipeline ğŸš€

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0%2B-orange)
![Flask](https://img.shields.io/badge/Flask-2.0%2B-green)
![Docker](https://img.shields.io/badge/Docker-20.10%2B-blue)

A comprehensive end-to-end machine learning project demonstrating the complete lifecycle from data ingestion to model deployment. This project includes student performance prediction with automated ML pipeline deployment using Flask, Docker, and AWS.

## Features âœ¨

- Complete ML Pipeline Implementation
- Automated Data Ingestion and Preprocessing
- Custom Exception Handling
- Modular Project Structure
- Configurable Logging System
- Multiple Model Training & Evaluation
- Model Performance Tracking
- Flask Web Application
- Docker Containerization
- AWS Deployment Ready

## Project Architecture ğŸ—ï¸

```
End-to-End-ML/
â”œâ”€â”€ artifacts/
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ data/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â””â”€â”€ model_trainer.py
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ prediction_pipeline.py
â”‚   â”‚   â””â”€â”€ training_pipeline.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ home.html
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ application.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

## Installation & Setup ğŸ› ï¸

1. Clone the repository:
```bash
git clone https://github.com/zainhammagi12/End-to-End-ML-.git
cd End-to-End-ML-
```

2. Create and activate virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

## Project Components ğŸ“¦

### 1. Data Ingestion
- Automated data loading and splitting
- Train-test split configuration
- Data validation checks

### 2. Data Transformation
- Automated feature engineering
- Custom preprocessing pipeline
- Handling missing values
- Feature scaling and encoding

### 3. Model Training
- Multiple model evaluation:
  - RandomForestRegressor
  - Linear Regression
  - XGBoost
  - CatBoost
- Hyperparameter optimization
- Cross-validation
- Model performance metrics

### 4. Prediction Pipeline
- Real-time prediction capability
- Input validation
- Error handling
- Performance logging

## Usage ğŸš€

### Training Pipeline
```python
from src.pipeline.training_pipeline import train
model = train()
```

### Prediction
```python
from src.pipeline.prediction_pipeline import predict
result = predict(input_data)
```

### Web Application
```bash
python application.py
```

### Docker Deployment
```bash
docker build -t ml-pipeline .
docker run -p 5000:5000 ml-pipeline
```

## Model Performance ğŸ“Š

- RÂ² Score: 0.92
- MAE: 4.23
- MSE: 27.89
- RMSE: 5.28

## Configuration âš™ï¸

Key configurations can be modified in `config.yaml`:
```yaml
data_path: "data/student_data.csv"
model_params:
  random_forest:
    n_estimators: 100
    max_depth: 10
  xgboost:
    learning_rate: 0.1
    max_depth: 7
```

## API Reference ğŸ“š

### Prediction Endpoint
```http
POST /predict
Content-Type: application/json

{
  "reading_score": 75,
  "writing_score": 82,
  "parental_education": "bachelor's degree",
  "lunch": "standard"
}
```

## Logging System ğŸ“

- Comprehensive logging implementation
- Separate logs for training and prediction
- Custom exception tracking
- Performance monitoring

## Testing ğŸ§ª

Run tests using:
```bash
python -m pytest tests/
```

## Contributing ğŸ¤

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

## Future Improvements ğŸ”®

- [ ] Add model versioning system
- [ ] Implement A/B testing capability
- [ ] Add more ML algorithms
- [ ] Enhance API documentation
- [ ] Add real-time monitoring dashboard
- [ ] Implement automated retraining
- [ ] Add support for different data formats

## Author âœï¸

Mohammad Hammagi
- LinkedIn: [Zain Hammagi](https://www.linkedin.com/in/zain-hammagi)
- GitHub: [@zainhammagi12](https://github.com/zainhammagi12)

## License ğŸ“„

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments ğŸ™

- Scikit-learn documentation
- Flask documentation
- Docker community
- AWS documentation
